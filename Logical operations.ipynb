{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sovling LINE problem with a single perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11]]).to(device)\n",
    "Y = torch.FloatTensor([[5], [8], [11], [14], [17], [20], [23], [26], [29], [32], [35], [38]]).to(device) # 3x+5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Linear = Applies a linear transformation to the incoming data: Y = w*X^T+b\n",
    "\n",
    "nn.Sigmoid: Applies the element-wise sigmoid function\n",
    "\n",
    "<img src=\"https://pytorch.org/docs/stable/_images/Sigmoid.png\">\n",
    "\n",
    "References:\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron model\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(1, 1, bias=True),\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weights: Parameter containing:\n",
      "tensor([[-0.7049]], requires_grad=True)\n",
      "Starting bias: Parameter containing:\n",
      "tensor([0.4947], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting weights: {}\".format(model[0].weight))\n",
    "print(\"Starting bias: {}\".format(model[0].bias))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [TODO] loss and optimizer significance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  loss: 307.0710754394531\n",
      "step: 1000  loss: 7.259591075126082e-05\n",
      "step: 2000  loss: 1.107101410546818e-09\n",
      "step: 3000  loss: 5.492021837305572e-10\n",
      "step: 4000  loss: 5.492021837305572e-10\n"
     ]
    }
   ],
   "source": [
    "for step in range(5000):\n",
    "    pred = model(X)\n",
    "    loss = criterion(pred, Y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 1000==0:\n",
    "        print('step:', step, \" loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.0000],\n",
      "        [ 8.0000],\n",
      "        [11.0000],\n",
      "        [14.0000],\n",
      "        [17.0000],\n",
      "        [20.0000],\n",
      "        [23.0000],\n",
      "        [26.0000],\n",
      "        [29.0000],\n",
      "        [32.0000],\n",
      "        [35.0000],\n",
      "        [38.0000]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred = model(X)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[41.0000]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "new_value = torch.FloatTensor([[12]]).to(device)\n",
    "new_pred = model(new_value)\n",
    "print(new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting weights: tensor([3.0000], grad_fn=<ReshapeAliasBackward0>)\n",
      "Starting bias: Parameter containing:\n",
      "tensor([5.0000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Learned weights: {}\".format(model[0].weight.flatten()))\n",
    "print(\"Learned bias: {}\".format(model[0].bias.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sovling OR problem with a single perceptron\n",
    "\n",
    "| x1 | x2 | y |\n",
    "|:--:|:--:|:-:|\n",
    "|  0 |  0 | 0 |\n",
    "|  0 |  1 | 1 |\n",
    "|  1 |  0 | 1 |\n",
    "|  1 |  1 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [1]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single neuron Perceptron model\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(2, 1, bias=True), \n",
    "            nn.Sigmoid()\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  loss: 0.15306387841701508\n",
      "step: 200  loss: 0.09753914177417755\n",
      "step: 400  loss: 0.07150579988956451\n",
      "step: 600  loss: 0.0548553392291069\n",
      "step: 800  loss: 0.04369859769940376\n",
      "step: 1000  loss: 0.035865042358636856\n",
      "step: 1200  loss: 0.03014693595468998\n",
      "step: 1400  loss: 0.025836311280727386\n",
      "step: 1600  loss: 0.022497672587633133\n",
      "step: 1800  loss: 0.01985195465385914\n",
      "step: 2000  loss: 0.0177138764411211\n",
      "step: 2200  loss: 0.01595669612288475\n",
      "step: 2400  loss: 0.014491286128759384\n",
      "step: 2600  loss: 0.01325354166328907\n",
      "step: 2800  loss: 0.01219630241394043\n",
      "step: 3000  loss: 0.011284248903393745\n",
      "step: 3200  loss: 0.010490469634532928\n",
      "step: 3400  loss: 0.009794162586331367\n",
      "step: 3600  loss: 0.009179039858281612\n",
      "step: 3800  loss: 0.008632124401628971\n",
      "step: 4000  loss: 0.008143034763634205\n",
      "step: 4200  loss: 0.007703353185206652\n",
      "step: 4400  loss: 0.007306162267923355\n",
      "step: 4600  loss: 0.006945773493498564\n",
      "step: 4800  loss: 0.006617441773414612\n"
     ]
    }
   ],
   "source": [
    "for step in range(5000):\n",
    "    pred = model(X)\n",
    "    loss = criterion(pred, Y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 200==0:\n",
    "        print('step:', step, \" loss:\", loss.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [TODO] show graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1200],\n",
      "        [0.9264],\n",
      "        [0.9263],\n",
      "        [0.9991]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred = model(X)\n",
    "print(pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TODO] add thresholding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving AND problem with a single perceptron\n",
    "\n",
    "| x1 | x2 | y |\n",
    "|:--:|:--:|:-:|\n",
    "|  0 |  0 | 0 |\n",
    "|  0 |  1 | 0 |\n",
    "|  1 |  0 | 0 |\n",
    "|  1 |  1 | 1 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [TODO] Format of data for batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [0], [0], [1]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron model\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(2, 1, bias=True), \n",
    "            nn.Sigmoid()\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  loss: 0.20026694238185883\n",
      "step: 1000  loss: 0.05582744628190994\n",
      "step: 2000  loss: 0.031272247433662415\n",
      "step: 3000  loss: 0.020983580499887466\n",
      "step: 4000  loss: 0.01551942341029644\n"
     ]
    }
   ],
   "source": [
    "for step in range(5000):\n",
    "    pred = model(X)\n",
    "    loss = criterion(pred, Y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 1000==0:\n",
    "        print('step:', step, \" loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0030],\n",
      "        [0.1191],\n",
      "        [0.1191],\n",
      "        [0.8571]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred = model(X)\n",
    "print(pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving XOR problem with a single perceptron\n",
    "\n",
    "| x1 | x2 | y |\n",
    "|:--:|:--:|:-:|\n",
    "|  0 |  0 | 0 |\n",
    "|  0 |  1 | 1 |\n",
    "|  1 |  0 | 1 |\n",
    "|  1 |  1 | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron model\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(2, 1, bias=True), \n",
    "            nn.Sigmoid()\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  loss: 0.28076133131980896\n",
      "step: 1000  loss: 0.25000685453414917\n",
      "step: 2000  loss: 0.25000008940696716\n",
      "step: 3000  loss: 0.2499999850988388\n",
      "step: 4000  loss: 0.2499999850988388\n"
     ]
    }
   ],
   "source": [
    "for step in range(5000):\n",
    "    pred = model(X)\n",
    "    loss = criterion(pred, Y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 1000==0:\n",
    "        print('step:', step, \" loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.5000]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred = model(X)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron model\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(2, 2, bias=True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(2, 1, bias=True), \n",
    "            nn.Sigmoid()\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  loss: 0.7511292099952698\n",
      "step: 2000  loss: 0.679911732673645\n",
      "step: 4000  loss: 0.4593662619590759\n"
     ]
    }
   ],
   "source": [
    "for step in range(5000):\n",
    "    pred = model(X)\n",
    "    loss = criterion(pred, Y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 2000==0:\n",
    "        print('step:', step, \" loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0521],\n",
      "        [0.9203],\n",
      "        [0.4954],\n",
      "        [0.5314]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred = model(X)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "443dc6aef4bf313d5f038dcfb521c9759bd40586a60374df23c4f50260c810a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
