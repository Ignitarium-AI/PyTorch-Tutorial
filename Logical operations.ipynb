{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the LINE problem with a single perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line equation: y = w*x + c\n",
    "w = 3\n",
    "c = 5\n",
    "X = torch.FloatTensor([[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11]]).to(device)\n",
    "Y = torch.FloatTensor([[w*x+c] for x in range(12)]).to(device)\n",
    "# Y = torch.FloatTensor([[5], [8], [11], [14], [17], [20], [23], [26], [29], [32], [35], [38]]).to(device) # 3x+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron model\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(1, 1, bias=True),\n",
    "        ).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Linear = Applies a linear transformation to the incoming data: Y = w*X^T+b\n",
    "\n",
    "References:\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting weights: {}\".format(model[0].weight))\n",
    "print(\"Starting bias: {}\".format(model[0].bias))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss and optimizer\n",
    "loss: loss function is a method of evaluating how well your machine learning algorithm models your featured data set.\n",
    "\n",
    "optimizer: optimizers are algorithms or methods used to change the parameters of your neural network such as weights and learning rate in order to reduce the loss.\n",
    "\n",
    "MSELoss: $\\frac{1}{n}\\sum (y - \\hat{y})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(5000):\n",
    "    pred = model(X)\n",
    "    loss = criterion(pred, Y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 200==0:\n",
    "        print('step:', step, \" loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_value = torch.FloatTensor([[12]]).to(device)\n",
    "new_pred = model(new_value)\n",
    "print(new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Learned weights: {}\".format(model[0].weight))\n",
    "print(\"Learned bias: {}\".format(model[0].bias))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving OR problem with a single perceptron\n",
    "\n",
    "| x1 | x2 | y |\n",
    "|:--:|:--:|:-:|\n",
    "|  0 |  0 | 0 |\n",
    "|  0 |  1 | 1 |\n",
    "|  1 |  0 | 1 |\n",
    "|  1 |  1 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [1]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(2, 1, bias=True), \n",
    "            nn.Sigmoid()\n",
    "        ).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Sigmoid: Applies the element-wise sigmoid function\n",
    "\n",
    "<img src=\"https://pytorch.org/docs/stable/_images/Sigmoid.png\">\n",
    "\n",
    "References:\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detach() method in PyTorch is used to separate a tensor from the computational graph by returning a new tensor that doesn't require a gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for step in range(5000):\n",
    "    pred = model(X)\n",
    "    loss = criterion(pred, Y)\n",
    "    losses.append(loss.detach().numpy())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 200==0:\n",
    "        print('step:', step, \" loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list(range(5000)), losses)\n",
    "plt.title(\"Loss graph\")\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.ylabel(\"Steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X)\n",
    "print(pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholding to obtain the 0 or 1 as final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 1 * (pred >= 0.5)\n",
    "print(out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving AND problem with a single perceptron\n",
    "\n",
    "| x1 | x2 | y |\n",
    "|:--:|:--:|:-:|\n",
    "|  0 |  0 | 0 |\n",
    "|  0 |  1 | 0 |\n",
    "|  1 |  0 | 0 |\n",
    "|  1 |  1 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [0], [0], [1]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron model\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(2, 1, bias=True), \n",
    "            nn.Sigmoid()\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(5000):\n",
    "    pred = model(X)\n",
    "    loss = criterion(pred, Y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 200==0:\n",
    "        print('step:', step, \" loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 1 * (pred >= 0.5)\n",
    "print(out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving XOR problem with a single perceptron\n",
    "\n",
    "| x1 | x2 | y |\n",
    "|:--:|:--:|:-:|\n",
    "|  0 |  0 | 0 |\n",
    "|  0 |  1 | 1 |\n",
    "|  1 |  0 | 1 |\n",
    "|  1 |  1 | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron model\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(2, 1, bias=True), \n",
    "            nn.Sigmoid()\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(5000):\n",
    "    pred = model(X)\n",
    "    loss = criterion(pred, Y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 200==0:\n",
    "        print('step:', step, \" loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron model\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(2, 2, bias=True),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(2, 1, bias=True), \n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(5000):\n",
    "    pred = model(X)\n",
    "    loss = criterion(pred, Y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 200==0:\n",
    "        print('step:', step, \" loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 1 * (pred >= 0.5)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "443dc6aef4bf313d5f038dcfb521c9759bd40586a60374df23c4f50260c810a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
